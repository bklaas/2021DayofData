{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:18:29.961405Z",
     "iopub.status.busy": "2021-01-08T21:18:29.960895Z",
     "iopub.status.idle": "2021-01-08T21:18:29.967304Z",
     "shell.execute_reply": "2021-01-08T21:18:29.966207Z",
     "shell.execute_reply.started": "2021-01-08T21:18:29.961278Z"
    }
   },
   "source": [
    "# 2020 University of Minnesota Day of Data Python Notebook\n",
    "# Exploration of American Community Survey data extracted from IPUMS-USA (https://ipums.org), a product of the U of M's Institute for Social Research and Data Innovation (ISRDI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:18:29.961405Z",
     "iopub.status.busy": "2021-01-08T21:18:29.960895Z",
     "iopub.status.idle": "2021-01-08T21:18:29.967304Z",
     "shell.execute_reply": "2021-01-08T21:18:29.966207Z",
     "shell.execute_reply.started": "2021-01-08T21:18:29.961278Z"
    }
   },
   "source": [
    "## Python libraries, whether part of the standard set of Python libraries or from 3rd party sources, need to be imported. These are the libraries that we'll make use of in this notebook:\n",
    "*  Pandas is a Python library for reading and manipulating tabular data. think \"programmatic spreadsheets\" \n",
    "*  Numpy is a number-processing library that pandas works closely with\n",
    "*  BeautifulSoup is a library that can parse misc. markup languages, including XML\n",
    "*  Altair is one of python's many data viz libariers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a Python library for reading and manipulating tabular data. think \"programatic spreadsheets\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start by reading in the data into a Pandas dataframe.\n",
    "### The data file is in (gzipped) csv, which Pandas can read into a dataframe via its built-in read_csv() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/usa_00071.csv.gz\")\n",
    "\n",
    "# the variable HHINCOME will show all 9s for no response, so let's change those to np.nan (which means \"blank\")\n",
    "data[\"HHINCOME\"] = data[\"HHINCOME\"].replace(9999999, np.nan)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In addition to the data, we have metadata that describes the data. This includes an XML file that maps the variables' numeric codes (how survey answers are represented in the data) to understandable labels.\n",
    "### these two helper methods are for getting label information out of a provided XML file and into a codebook dict to translate data codes->labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method takes in information on a given variable and returns a code-to-label dictionary for that variable\n",
    "def parse_var_xml(var):\n",
    "    var_values = {}\n",
    "    for cat in var.find_all(\"catgry\"):\n",
    "        var_values[int(cat.catvalu.text)] = cat.labl.text\n",
    "        \n",
    "    return var_values\n",
    "\n",
    "# Use Beautiful Soup to parse XML and send blocks of variable info to the parse_var_xml() method\n",
    "# This method returns a codebook, which is a Pthon dict of dicts. Each top-level key is a variable, with values as a dice of code-to-label translations for that variable\n",
    "def ipums_xml_to_var_dicts(xml_file):\n",
    "    with open(xml_file, \"r\") as file:\n",
    "        content = file.readlines()\n",
    "        content = \"\".join(content)\n",
    "        bs_content = BS(content, \"lxml\")\n",
    "    variables = bs_content.find_all(\"var\")\n",
    "    codebook = {}\n",
    "    for var in variables:\n",
    "        codebook[var.get(\"name\")] = parse_var_xml(var)\n",
    "    \n",
    "    return codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:33:19.833551Z",
     "iopub.status.busy": "2021-01-08T21:33:19.833138Z",
     "iopub.status.idle": "2021-01-08T21:33:19.838290Z",
     "shell.execute_reply": "2021-01-08T21:33:19.837009Z",
     "shell.execute_reply.started": "2021-01-08T21:33:19.833500Z"
    }
   },
   "source": [
    "## Now that the methods are defined, to populate a codebook is simple: send the XML file to ipums_xml_to_var_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of variable codes-to-labels for each variable\n",
    "var_val_labels = ipums_xml_to_var_dicts(\"../syntax/usa_00071.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look at one variable dictionary, TRANWORK (mode of transportation to get to work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_val_labels['TRANWORK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the var_val_labels dictionary, add columns for every variable's label value with the column name \\<VARIABLE\\>_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_val_labels.keys():\n",
    "    data[f\"{var}_lbl\"] = data[var].map(var_val_labels[var])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can actually start doing simple visualizations [right from pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)\n",
    "\n",
    "## Say we wanted to plot a trend line of \"Prime Age Workers\" (age 25-54) in our data.\n",
    "* First we would subset down to just prime age workers,\n",
    "* Then count by year and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to leave the data in Year-sort-order, but value_counts() tries to sort\n",
    "# by, well, value counts. So we turn that sorting off.\n",
    "data[data[\"AGE\"].between(25,54)][\"YEAR\"].value_counts(sort=False).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it looks like there was a massive spike in prime working age folks, make sure you pay attention to that Y-axis, the bottom value is not zero. In fact, let's take care of that right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"AGE\"].between(25,54)][\"YEAR\"].value_counts(sort=False).plot(ylim=(0,125000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more like it. But also very boring... \n",
    "\n",
    "If we want to make some more engaging visualizations we have to manipulate the data a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At this point we have a dataframe in which each row represents a single person\n",
    "\n",
    "### We want to look at modes of transportation \"prime age\" workers use. So, first we subset our data down to those with an EMPSTAT of 1 (working) and those between 25 and 54 inclusive (prime working age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = data[data['EMPSTAT']==1 & data[\"AGE\"].between(25,54)]\n",
    "workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To explore the data visually, create a dataframe that represents aggregate summary data\n",
    "### Specifically, a dataframe in which each row represents a Year and City and the columns contain labels and counts for various variables\n",
    "### To take the raw data and obtain counts of each City (CITY_lbl) by Year (YEAR) by type of transportation (TRANWORK_lbl), use the Pandas crosstab() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.crosstab(index=[workers[\"YEAR\"],\n",
    "                        workers[\"CITY_lbl\"],\n",
    "                        workers[\"TRANWORK_lbl\"]],\n",
    "                 columns=\"count\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:56:33.109777Z",
     "iopub.status.busy": "2021-01-08T21:56:33.109505Z",
     "iopub.status.idle": "2021-01-08T21:56:33.114146Z",
     "shell.execute_reply": "2021-01-08T21:56:33.112941Z",
     "shell.execute_reply.started": "2021-01-08T21:56:33.109749Z"
    }
   },
   "source": [
    "## This crosstab dataframe puts YEAR, CITY_lbl, and TRANWORK_lbl as indexes to the dataframe. We want them as columns, which is done with the dataframe's reset_index() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here we need to go one step further. The data are in the format where each line shows a count for a particular type of transportation for a given year and city. We want to end up with the counts of the various transportation modes as columns, with one row per city/year\n",
    "## This can be accomplished with a pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = df.pivot_table(index=[\"YEAR\", \"CITY_lbl\"],\n",
    "                       columns=\"TRANWORK_lbl\",\n",
    "                       values=\"count\",\n",
    "                       aggfunc='sum',\n",
    "                       margins=True,\n",
    "                       fill_value=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple pieces of cleanup. \n",
    "* First we want the indexes as columns, so as before we reset_index()\n",
    "* Second, we do not need the \"All\" row that represents the counts of all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.reset_index()\n",
    "# Drop the All row (YEAR==\"All\")\n",
    "table = table[table[\"YEAR\"]!=\"All\"]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To compare across cities, raw counts are not sufficient (as each city have different amount of survey respondents)\n",
    "### Create new columns that represent the RATIO of a given transporation mode to the total count of responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df[\"TRANWORK_lbl\"].unique():\n",
    "    table[f\"% {col}\"] = (table[col] / table[\"All\"])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Let's graph some data!\n",
    "\n",
    "## While there are a ton of graphing libaries for Python (check out [Pyviz](https://pyviz.org/tools.html) for a fairly comprehensive list of viable options), we are going to be using [Altair](https://altair-viz.github.io/user_guide/customization.html\n",
    "\n",
    "## First, we can try to compare percent of working population working from home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = alt.Chart(table).mark_line(interpolate=\"natural\").encode(\n",
    "    alt.X('YEAR:O'),\n",
    "    alt.Y('% Worked at home:Q'),\n",
    "    alt.Color('CITY_lbl'),\n",
    ").properties(width=500, height=500)\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well. That's a mess.\n",
    "## How about we scale this back a bit...Just % Worked at home for the year 2019, and display it as a vertical bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with just a 1 year\n",
    "one_year = table[table[\"YEAR\"]==2019]\n",
    "bar = alt.Chart(one_year, title=\"2019\").mark_bar().encode(\n",
    "        alt.X('% Worked at home'),\n",
    "        alt.Y('CITY_lbl:N'),\n",
    "    )\n",
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better! But, hard to compare without these ranked by value...\n",
    "## Use sort=\"-x\" on the Y axis to sort in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort based on X value\n",
    "one_year = table[table[\"YEAR\"]==2019]\n",
    "bar = alt.Chart(one_year, title=\"2019\").mark_bar().encode(\n",
    "        alt.X('% Worked at home'),\n",
    "        alt.Y('CITY_lbl:N', sort=\"-x\"),\n",
    "    )\n",
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool. Cool Cool Cool. Now that we've got 2019 displaying nicely, let's show every year with the .hconcat() multiple chart feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple years\n",
    "charts = alt.hconcat()\n",
    "for y in table[\"YEAR\"].unique():\n",
    "    one_year = table[table[\"YEAR\"]==y]\n",
    "    bar = alt.Chart(one_year, title=str(y)).mark_bar().encode(\n",
    "        alt.X('% Worked at home'),\n",
    "        alt.Y('CITY_lbl:N', sort=\"-x\"),\n",
    "    ).properties(width=150)\n",
    "    charts |= bar\n",
    "    \n",
    "charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lovely! Now that we're to this point, let's do some tidying up.\n",
    "* Add a title for the set of charts\n",
    "* The Y-axis label CITY_Lbl is unneeded\n",
    "* Whoops, % Worked at home is displaying ratios not percentages. Fix that formatting\n",
    "* Finally, make the X-axis range across each chart consistent by finding the max x value across all years and create the scale based on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistent X axis range\n",
    "charts = alt.hconcat(title=\"City rankings for % Working at Home\")\n",
    "max_pct = table[\"% Worked at home\"].max()\n",
    "for y in table[\"YEAR\"].unique():\n",
    "    bar = alt.Chart(table[table[\"YEAR\"]==y], title=str(y)).mark_bar().encode(\n",
    "        alt.X(\n",
    "            '% Worked at home',\n",
    "            axis=alt.Axis(format=\"%\"),\n",
    "            scale=alt.Scale(domain=(0, max_pct)),\n",
    "        ),\n",
    "        alt.Y('CITY_lbl:N', sort=\"-x\", title=None),\n",
    "    ).properties(width=150)\n",
    "    charts |= bar\n",
    "    \n",
    "charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excellent!\n",
    "## Now that we're nicely cleaned up, let's highlight a city of interest using alt.condition()\n",
    "## Let's take a look at the great city of Minneapolis by making its bar yellow across each chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional coloring of one bar\n",
    "charts = alt.hconcat(title=\"City rankings for % Working at Home (age 25-55)\")\n",
    "max_pct = table[\"% Worked at home\"].max()\n",
    "for y in table[\"YEAR\"].unique():\n",
    "    bar = alt.Chart(table[table[\"YEAR\"]==y], title=str(y)).mark_bar().encode(\n",
    "        alt.X(\n",
    "            '% Worked at home',\n",
    "            axis=alt.Axis(format=\"%\"),\n",
    "            scale=alt.Scale(domain=(0, max_pct)),\n",
    "        ),\n",
    "        alt.Y('CITY_lbl:N', sort=\"-x\", title=None),\n",
    "        color=alt.condition(\n",
    "            alt.datum.CITY_lbl == \"Minneapolis, MN\",\n",
    "            alt.value('orange'),\n",
    "            alt.value('steelblue'),\n",
    "        )\n",
    "    ).properties(width=150)\n",
    "    charts |= bar\n",
    "    \n",
    "charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using the same code but pointing to % Bicycle, we can produce the same type of graphs for different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional coloring of one bar\n",
    "charts = alt.hconcat(title=\"City rankings for % Biking to work (age 25-55)\")\n",
    "max_pct = table[\"% Bicycle\"].max()\n",
    "for y in table[\"YEAR\"].unique():\n",
    "    bar = alt.Chart(table[table[\"YEAR\"]==y], title=str(y)).mark_bar().encode(\n",
    "        alt.X(\n",
    "            '% Bicycle',\n",
    "            axis=alt.Axis(format=\"%\"),\n",
    "            scale=alt.Scale(domain=(0, max_pct)),\n",
    "        ),\n",
    "        alt.Y('CITY_lbl:N', sort=\"-x\", title=None),\n",
    "        color=alt.condition(\n",
    "            alt.datum.CITY_lbl == \"Minneapolis, MN\",\n",
    "            alt.value('orange'),\n",
    "            alt.value('steelblue'),\n",
    "        )\n",
    "    ).properties(width=150)\n",
    "    charts |= bar\n",
    "    \n",
    "charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------\n",
    "---------------------------------------------------------\n",
    "---------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bk-dataviz (py3.9)",
   "language": "python",
   "name": "bk-dataviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
